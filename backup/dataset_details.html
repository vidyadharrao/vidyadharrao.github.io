<html>
<body>
Dataset: ImageCLEFF <br>
Size: 10200 <br>
Classes: 34 <br>
Training Samples: 6800 (200 per class)<br>
Testing Samples: 3400 (100 per class)<br>
Kernel: Kchi2 <br>
vocabsize: 800

<br>
	<table border="1">
	<caption>Precision at 20 for each class with and without diversity</caption>
		<tr><td> no diversity </td><td> 0.45</td> <td> 0.10</td> <td> 0.15</td> <td> 0.05</td> <td> 0.00</td> <td> 0.05</td> <td> 0.00</td> <td> 0.10</td> <td> 0.00</td> <td> 0.05</td> <td> 0.00</td> <td> 0.00</td> <td> 0.05</td> <td> 0.00</td> <td> 0.15</td> <td> 0.05</td> <td> 0.05</td> <td> 0.05</td> <td> 0.05</td> <td> 0.45</td> <td> 0.05</td> <td> 0.10</td> <td> 0.25</td> <td> 0.15</td> <td> 0.20</td> <td> 0.00</td> <td> 0.60</td> <td> 0.45</td> <td> 0.50</td> <td> 0.45</td> <td> 0.15</td> <td> 0.55</td> <td> 0.80</td> <td> 0.05</td> </tr>
		<tr><td> with diversity </td> <td> 0.25 </td><td> 0.20 </td><td> 0.15 </td><td> 0.00 </td><td> 0.00 </td><td> 0.00 </td><td> 0.05 </td><td> 0.05 </td><td> 0.00 </td><td> 0.00 </td><td> 0.10 </td><td> 0.05 </td><td> 0.00 </td><td> 0.05 </td><td> 0.10 </td><td> 0.10 </td><td> 0.15 </td><td> 0.10 </td><td> 0.00 </td><td> 0.10 </td><td> 0.05 </td><td> 0.10 </td><td> 0.20 </td><td> 0.10 </td><td> 0.05 </td><td> 0.00 </td><td> 0.15 </td><td> 0.10 </td><td> 0.15 </td><td> 0.20 </td><td> 0.00 </td><td> 0.25 </td><td> 0.35 </td><td> 0.05 </td>
</tr>
	</table>
<br>
<table border="1">
<caption> Retrieved images and annotations for query class1 with nodiversity(left) and diversity(right)</caption>
<tr>
	<td><img src="imagecleff-01-images.png" width="600" height="500" /> </td>
	<td><img src="greedy_imagecleff-01-images.png" width="600" height="500" /></td>
<tr>
</table>
</body>
</html>
